{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNR 650 - Advanced topics in deep learning for image analysis\n",
    "### Assignment 1: ResNet-18 on CIFAR10 with few training samples per class\n",
    "> The task is to take the structure of ResNet-18 model, and train it from scratch on CIFAR10 data, but take very few samples per class. After training, check the test performance. Check the magnitudes of the weights, visualize the kernels at different layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.5, 0.5, 0.5])\n",
    "inv_mean = -mean\n",
    "inv_std = 1/std\n",
    "max_n = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 40\n",
    "print_summary = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing & Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean = mean, \n",
    "                                                            std = std)])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean = mean, \n",
    "                                                            std = std)])\n",
    "\n",
    "# For the purposes of visualizing images\n",
    "inv_transforms = transforms.Compose([transforms.Normalize(mean = (0., 0., 0.),\n",
    "                                                          std = inv_std),\n",
    "                                     transforms.Normalize(mean = inv_mean,\n",
    "                                                          std = (1., 1., 1,))])\n",
    "\n",
    "cifar10 = datasets.CIFAR10(root = './data/', train=True, transform=train_transforms, download=True)\n",
    "cifar10_test = datasets.CIFAR10(root='./data/', train=False, transform=test_transforms, download=True)\n",
    "cifar10_classes = cifar10.classes\n",
    "images, labels = cifar10.data, np.array(cifar10.targets)\n",
    "test_images, test_labels = cifar10_test.data, np.array(cifar10_test.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing CIFAR 10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_per_class = 10\n",
    "fig, axes = plt.subplots(nrows=num_per_class, ncols=len(cifar10_classes), figsize = (10,10))\n",
    "for idx, cls_name in enumerate(cifar10_classes):\n",
    "    lbl_idxs = np.where(labels == idx)[0]\n",
    "    for row in range(num_per_class):\n",
    "        disp_idx = random.choice(lbl_idxs)\n",
    "        img = images[disp_idx]\n",
    "        axes[idx][row].imshow(img)\n",
    "        if row == 0:\n",
    "            axes[idx][row].set_ylabel(cls_name)\n",
    "            axes[idx][row].set_xticks([])\n",
    "            axes[idx][row].set_yticks([])\n",
    "            continue\n",
    "        axes[idx][row].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Datasets: Subset & Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idxs_subset = []                           # 100 training images per class\n",
    "data_idxs_full = []                             # 5000 training images per class\n",
    "for idx, _ in enumerate(cifar10_classes):   \n",
    "    lbl_idxs = np.where(labels == idx)[0]\n",
    "    idxs_subset = np.random.choice(lbl_idxs, max_n, replace=False)\n",
    "    data_idxs_subset.extend(idxs_subset)\n",
    "    data_idxs_full.extend(lbl_idxs)\n",
    "print(\"Size of subset dataset: \", len(data_idxs_subset))        # 100 x 10 = 1000\n",
    "print(\"Size of full dataset: \", len(data_idxs_full))            # 5000 x 10 = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing CIFAR 10 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10(Dataset):\n",
    "    def __init__(self, images, labels, idxs, transform = None):\n",
    "        self.images = images[idxs]\n",
    "        self.labels = labels[idxs]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        lbl = self.labels[idx]\n",
    "        if self.transform:\n",
    "            if not isinstance(img, torch.Tensor):\n",
    "                img = Image.fromarray(img)\n",
    "                img = self.transform(img)\n",
    "        return img, lbl\n",
    "    \n",
    "# Create two datasets, one for subset and one for full\n",
    "train_dataset_subset = Cifar10(images, labels, data_idxs_subset, train_transforms)\n",
    "train_dataset_full = Cifar10(images, labels, data_idxs_full, train_transforms)\n",
    "test_dataset = Cifar10(test_images, test_labels, list(range(len(test_images))), test_transforms)\n",
    " \n",
    "# Create DataLoaders\n",
    "trainloader_subset = DataLoader(train_dataset_subset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "trainloader_full = DataLoader(train_dataset_full, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainloader, testloader, model_name, print_summary, regularize = False):\n",
    "    model = models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(cifar10_classes))\n",
    "    model = model.to(device)\n",
    "    if print_summary:\n",
    "        summary(model=model, input_size=(3,32,32))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if regularize:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.05)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    test_accuracy = []\n",
    "    best_test_accuracy = 0.0\n",
    "    best_train_accuracy = 0.0\n",
    "\n",
    "    # Save Names\n",
    "    best_model = f'best_model_{model_name}'\n",
    "    final_model = f'{model_name}'\n",
    "    if regularize:\n",
    "        best_model+='_regularize'\n",
    "        final_model+='_regularize'\n",
    "\n",
    "    print(f\"Training {model_name}\")\n",
    "    for epoch in range(1, epochs+1):\n",
    "        pbar = tqdm(trainloader, total=len(trainloader), leave=False)\n",
    "        epoch_loss = 0.0\n",
    "        model.train()\n",
    "        for imgs, lbls in pbar:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, lbls)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix(train_loss=loss.item())\n",
    "\n",
    "        epoch_loss = epoch_loss / len(trainloader)\n",
    "        model.eval()\n",
    "        no_of_correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, lbls in trainloader:\n",
    "                imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "                out = model(imgs)\n",
    "                _, preds = out.max(-1)\n",
    "                no_of_correct += (preds == lbls).cpu().numpy().sum()\n",
    "                total += len(lbls)\n",
    "\n",
    "        epoch_accuracy = no_of_correct / total\n",
    "        losses.append(epoch_loss)\n",
    "        accuracy.append(epoch_accuracy)\n",
    "\n",
    "\n",
    "        no_of_correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, lbls in testloader:\n",
    "                imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "                out = model(imgs)\n",
    "                _, preds = out.max(-1)\n",
    "                no_of_correct += (preds == lbls).cpu().numpy().sum()\n",
    "                total += len(lbls)\n",
    "\n",
    "        test_epoch_accuracy = no_of_correct / total\n",
    "        test_accuracy.append(test_epoch_accuracy)\n",
    "        if best_test_accuracy < test_epoch_accuracy:\n",
    "            best_test_accuracy = test_epoch_accuracy\n",
    "            torch.save(model.state_dict(), f'./model_weights/{best_model}.pt')\n",
    "        if best_train_accuracy < epoch_accuracy:\n",
    "            best_train_accuracy = epoch_accuracy\n",
    "            torch.save(model.state_dict(), f'./model_weights/{final_model}.pt')\n",
    "\n",
    "        print(f\"{'*'*10} EPOCH {epoch:2}/{epochs} {'*'*10}\")\n",
    "        print(f'''{\"#\"*33}\n",
    "Train Loss: {epoch_loss:5.3f}, Train Accuracy: {epoch_accuracy*100:5.2f}\n",
    "{\"#\"*33}''')\n",
    "    model.load_state_dict(torch.load(f'./model_weights/{final_model}.pt'))\n",
    "    return model,losses,accuracy,test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ResNet-18 on CIFAR10 Subset Dataset (100 training samples per class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_subset, losses_subset, \\\n",
    "accuracy_subset, test_accuracy_subset = train_model(trainloader_subset, testloader,\n",
    "                                                    \"ResNet18_Subset\", \n",
    "                                                    print_summary=print_summary,\n",
    "                                                    regularize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Regularized ResNet-18 on CIFAR10 Subset Dataset (100 training samples per class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_subset_reg, losses_subset_reg, \\\n",
    "accuracy_subset_reg, test_accuracy_subset_reg = train_model(trainloader_subset, \n",
    "                                                    testloader,\n",
    "                                                    \"ResNet18_Subset\", \n",
    "                                                    print_summary=print_summary,\n",
    "                                                    regularize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ResNet-18 on CIFAR10 Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_full, losses_full, \\\n",
    "accuracy_full, test_accuracy_full = train_model(trainloader_full, testloader,\n",
    "                                                \"ResNet18_Full\", \n",
    "                                                print_summary=print_summary, \n",
    "                                                regularize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Regularized ResNet-18 on CIFAR10 Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_full_reg, losses_full_reg, \\\n",
    "accuracy_full_reg, test_accuracy_full_reg = train_model(trainloader_full, \n",
    "                                                testloader,\n",
    "                                                \"ResNet18_Full\", \n",
    "                                                print_summary=print_summary, \n",
    "                                                regularize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Training Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy_subset = accuracy_subset[-1]\n",
    "training_accuracy_full = accuracy_full[-1]\n",
    "training_accuracy_subset_reg = accuracy_subset_reg[-1]\n",
    "training_accuracy_full_reg = accuracy_full_reg[-1]\n",
    "print(f\"Training Accuracy of ResNet18 on subset CIFAR10 Dataset (Non Regularized):\\\n",
    " {training_accuracy_subset * 100:.2f}%\")\n",
    "print(f\"Training Accuracy of ResNet18 on full CIFAR10 Dataset (Non Regularized):\\\n",
    " {training_accuracy_full * 100:.2f}%\")\n",
    "print(f\"Training Accuracy of ResNet18 on subset CIFAR10 Dataset (Regularized):\\\n",
    " {training_accuracy_subset_reg * 100:.2f}%\")\n",
    "print(f\"Training Accuracy of ResNet18 on full CIFAR10 Dataset (Regularized):\\\n",
    " {training_accuracy_full_reg * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Test Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_accuracy_subset = test_accuracy_subset[-1]\n",
    "testing_accuracy_full = test_accuracy_full[-1]\n",
    "testing_accuracy_subset_reg = test_accuracy_subset_reg[-1]\n",
    "testing_accuracy_full_reg = test_accuracy_full_reg[-1]\n",
    "print(f\"testing Accuracy of ResNet18 on subset CIFAR10 Dataset (Non Regularized):\\\n",
    " {testing_accuracy_subset * 100:.2f}%\")\n",
    "print(f\"testing Accuracy of ResNet18 on full CIFAR10 Dataset (Non Regularized):\\\n",
    " {testing_accuracy_full * 100:.2f}%\")\n",
    "print(f\"testing Accuracy of ResNet18 on subset CIFAR10 Dataset (Regularized):\\\n",
    " {testing_accuracy_subset_reg * 100:.2f}%\")\n",
    "print(f\"testing Accuracy of ResNet18 on full CIFAR10 Dataset (Regularized):\\\n",
    " {testing_accuracy_full_reg * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Training Accuracy and Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].plot(accuracy_subset, label=\"ResNet18 on subset CIFAR10 Dataset\")\n",
    "axes[0].plot(accuracy_full, label=\"ResNet18 on full CIFAR10 Dataset\")\n",
    "axes[0].set_title('Training Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[0].annotate(f\"Subset Dataset: {training_accuracy_subset*100:.2f}%\", \n",
    "                 xy=(len(accuracy_subset)-1, training_accuracy_subset), \n",
    "                 xycoords='data',\n",
    "                 xytext=(-150, -50), \n",
    "                 textcoords='offset points',\n",
    "                 arrowprops=dict(arrowstyle=\"->\",\n",
    "                                 connectionstyle=\"arc3,rad=.2\"))\n",
    "\n",
    "axes[0].annotate(f\"Full Dataset: {training_accuracy_full*100:.2f}%\", \n",
    "                 xy=(len(accuracy_full)-1, training_accuracy_full), \n",
    "                 xycoords='data',\n",
    "                 xytext=(-150, -80), \n",
    "                 textcoords='offset points',\n",
    "                 arrowprops=dict(arrowstyle=\"->\",\n",
    "                                 connectionstyle=\"arc3,rad=.2\"))\n",
    "\n",
    "axes[1].plot(losses_subset, label=\"ResNet18 on subset CIFAR10 Dataset\")\n",
    "axes[1].plot(losses_full, label=\"ResNet18 on full CIFAR10 Dataset\")\n",
    "axes[1].set_title('Training Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy for train and test set\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].plot(accuracy_subset, label=\"Train Accuracy\")\n",
    "axes[0].plot(test_accuracy_subset, label=\"Test Accuracy\")\n",
    "axes[0].set_title('Training Accuracy (Subset)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(accuracy_full, label=\"Train Accuracy\")\n",
    "axes[1].plot(test_accuracy_full, label=\"Test Accuracy\")\n",
    "axes[1].set_title('Training Accuracy (Full)')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Weight Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_subset = models.resnet18(weights=None)\n",
    "best_subset.fc = nn.Linear(best_subset.fc.in_features, len(cifar10_classes))\n",
    "best_subset = best_subset.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_best_path = './model_weights/best_model_ResNet18_Subset.pt'\n",
    "best_subset.load_state_dict(torch.load(subset_best_path))\n",
    "models = [resnet18_subset, best_subset]\n",
    "model_names = [\"Overfit (Subset)\", \"Not Overfit (Subset)\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=18, ncols=2, figsize=(12, 36))\n",
    "conv_layer = 1\n",
    "\n",
    "for layer_index in range(18):\n",
    "    for model_index, model in enumerate(models):\n",
    "        current_layer = None\n",
    "        layer_count = 0\n",
    "        for layer in model.named_modules():\n",
    "            if layer[0].find('conv') != -1:\n",
    "                if layer_count == layer_index:\n",
    "                    current_layer = layer\n",
    "                    break\n",
    "                layer_count += 1\n",
    "            elif layer[0].find('fc') != -1 and layer_index == 17:  \n",
    "                current_layer = layer\n",
    "                break\n",
    "        \n",
    "        if current_layer:\n",
    "            layer_weights = current_layer[1].weight.cpu().detach().clone().numpy().reshape(-1, 1)\n",
    "            if current_layer[0].find('conv') != -1:\n",
    "                title = f\"Conv Layer {conv_layer} Weights\"\n",
    "                if model_index == 1:\n",
    "                    conv_layer += 1\n",
    "            else:\n",
    "                title = f\"FC Layer Weights\"\n",
    "            if layer_index == 0:\n",
    "                title = f\"{model_names[model_index]}\\n{title}\"\n",
    "            sns.distplot(x=layer_weights, ax=axes[layer_index, model_index]).set(title=title)\n",
    "            axes[layer_index, model_index].set_xlim(-0.5, 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_best_path = './model_weights/best_model_ResNet18_Full.pt'\n",
    "best_full = model.load_state_dict(torch.load(full_best_path))\n",
    "models = [resnet18_full, best_full]\n",
    "model_names = [\"Overfit (Full)\", \"Not Overfit (Full)\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=18, ncols=2, figsize=(12, 36))\n",
    "conv_layer = 1\n",
    "\n",
    "for layer_index in range(18):\n",
    "    for model_index, model in enumerate(models):\n",
    "        current_layer = None\n",
    "        layer_count = 0\n",
    "        for layer in model.named_modules():\n",
    "            if layer[0].find('conv') != -1:\n",
    "                if layer_count == layer_index:\n",
    "                    current_layer = layer\n",
    "                    break\n",
    "                layer_count += 1\n",
    "            elif layer[0].find('fc') != -1 and layer_index == 17:  \n",
    "                current_layer = layer\n",
    "                break\n",
    "        \n",
    "        if current_layer:\n",
    "            layer_weights = current_layer[1].weight.cpu().detach().clone().numpy().reshape(-1, 1)\n",
    "            if current_layer[0].find('conv') != -1:\n",
    "                title = f\"Conv Layer {conv_layer} Weights\"\n",
    "                if model_index == 1:\n",
    "                    conv_layer += 1\n",
    "            else:\n",
    "                title = f\"FC Layer Weights\"\n",
    "            if layer_index == 0:\n",
    "                title = f\"{model_names[model_index]}\\n{title}\"\n",
    "            sns.distplot(x=layer_weights, ax=axes[layer_index, model_index]).set(title=title)\n",
    "            axes[layer_index, model_index].set_xlim(-0.5, 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
